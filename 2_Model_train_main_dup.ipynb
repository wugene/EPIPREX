{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pgzip as gz\n",
    "import _pickle as pkl\n",
    "import gc\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Conv2D, MaxPool1D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X1: Seq, X2: Gene, Y: Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gz.open('TR_DATA/data_X1.pkl.gz') as f:\n",
    "    NP_seq = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gz.open('TR_DATA/data_X2_enc.pkl.gz') as f:\n",
    "    NP_gene = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gz.open('TR_DATA/data_Ys.pkl.gz') as f:\n",
    "    NP_peak = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_X1_SEQ = NP_seq.astype('float32')\n",
    "TR_X2_GENE = NP_gene.astype('float32')\n",
    "TR_Y_PEAK = NP_peak.astype('float32')\n",
    "\n",
    "TR_Y_ZERO = (TR_Y_PEAK < 0.1).astype('float32')\n",
    "\n",
    "TR_Y_W0_0 = 1/(TR_Y_ZERO.mean(axis=0, keepdims=True) + 0.01) + 0.01\n",
    "TR_Y_W1_0 = 1/(TR_Y_ZERO.mean(axis=1, keepdims=True) + 0.01) + 0.01\n",
    "TR_Y_W0_1 = 1/(1-1/TR_Y_W0_0)\n",
    "TR_Y_W1_1 = 1/(1-1/TR_Y_W1_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(name):\n",
    "\n",
    "    import hashlib\n",
    "    seed_sha = int(hashlib.sha256(model_id.encode('utf-8')).hexdigest(), 16) % 1000000\n",
    "\n",
    "    np.random.seed(seed_sha)\n",
    "    tf.random.set_seed(seed_sha+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'model_scmnt_1111'\n",
    "set_random_seed(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "epochs = 200\n",
    "learning_rate = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_latent = 10\n",
    "size_gene_input = TR_X2_GENE.shape[1]\n",
    "size_output = TR_Y_PEAK.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayers(tf.keras.layers.Layer):\n",
    "    def __init__(self, layer_params):\n",
    "        super(DenseLayers, self).__init__()\n",
    "        \n",
    "        L_layer = list()\n",
    "   \n",
    "        for x in layer_params:\n",
    "            if x<1:\n",
    "                l1 = Dropout(rate=x)\n",
    "            else:\n",
    "                l1 = Dense( x, activation=tf.nn.relu, kernel_initializer='GlorotNormal')\n",
    "            L_layer.append( l1 )\n",
    "\n",
    "        self.hidden_layer = L_layer\n",
    "\n",
    "    def call(self, input_features):\n",
    "        x = input_features\n",
    "        for l1 in self.hidden_layer:\n",
    "            x = l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayers(tf.keras.layers.Layer):\n",
    "    def __init__(self, layer_params):\n",
    "        super(ConvLayers, self).__init__()\n",
    "        \n",
    "        L_layer = list()\n",
    "   \n",
    "        for x in layer_params:\n",
    "            if len(x)==2:\n",
    "                n_kern, s_kern = x\n",
    "                l1  = Conv1D( n_kern, s_kern, activation='relu', kernel_initializer='GlorotNormal')\n",
    "            else:\n",
    "                n_pool = x[0]\n",
    "                l1 = MaxPool1D( n_pool )\n",
    "\n",
    "            L_layer.append( l1 )\n",
    "\n",
    "        self.hidden_layer = L_layer\n",
    "\n",
    "    def call(self, input_features):\n",
    "        x = input_features\n",
    "        for l1 in self.hidden_layer:\n",
    "            x = l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_relu1(x):\n",
    "    r = tf.minimum(tf.maximum(x, 0), 1)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class zScoreLayer(tf.keras.layers.Layer):\n",
    "    def call(self, a):\n",
    "        σ = tf.math.reduce_std (a, axis=0, keepdims=True)\n",
    "        μ = tf.math.reduce_mean(a, axis=0, keepdims=True)\n",
    "        return (a-μ)/σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SeqEncoder, self).__init__()\n",
    "\n",
    "        layer_params_conv = [(256, 11),    (128,  1),    [99],\n",
    "                             (128,  1),    [10] ]\n",
    "        \n",
    "        self.conv_layers = ConvLayers(layer_params_conv)\n",
    "        self.flatten_layer = Flatten()\n",
    "\n",
    "        layer_params_dense = [ 0.1, 256, 0.1 ]\n",
    "\n",
    "        self.dense_layers = DenseLayers(layer_params_dense)\n",
    "        self.output_layer = Dense( size_latent, activation=act_relu1, kernel_initializer='GlorotNormal' )\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        x = self.conv_layers(input_features)\n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.dense_layers(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneEnc2(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(GeneEnc2, self).__init__()\n",
    "\n",
    "        layer_params = [0.4, 32,\n",
    "                        0.1]\n",
    "         \n",
    "        self.hidden_layer = DenseLayers(layer_params)\n",
    "        self.output_layer = Dense( size_latent, activation=tf.nn.sigmoid, kernel_initializer='GlorotNormal' )\n",
    "        self.normal_layer = zScoreLayer()\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        x = self.hidden_layer(input_features)\n",
    "        x = self.output_layer(x)\n",
    "        return self.normal_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneDec2(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(GeneDec2, self).__init__()\n",
    "\n",
    "        layer_params = [64, 64]\n",
    "        \n",
    "        self.hidden_layer = DenseLayers(layer_params)\n",
    "        self.output_layer = Dense( size_gene_input, activation=tf.nn.sigmoid, kernel_initializer='GlorotNormal' )\n",
    "        self.normal_layer = zScoreLayer()\n",
    "        \n",
    "    def call(self, input_features):\n",
    "        x = self.hidden_layer(input_features)\n",
    "        x = self.output_layer(x)\n",
    "        return self.normal_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(dotLayer, self).__init__()\n",
    "        self.conv2d = Conv2D(1, 1, activation=act_relu1, kernel_initializer='GlorotNormal' )\n",
    "        self.weight_mask = tf.Variable( tf.random.uniform( (1, size_latent, size_output) ), trainable=True)\n",
    "        \n",
    "    def call(self, a, b):\n",
    "        # a = peaks x latent\n",
    "        # b = cells x latent\n",
    "        \n",
    "        bw = tf.multiply( self.weight_mask, tf.expand_dims(b, 2) )\n",
    "        c = tf.tensordot( a, bw, axes=[[1],[1]])\n",
    "        c_dimex = tf.expand_dims(c, -1)\n",
    "        c_conv = self.conv2d(c_dimex)\n",
    "        c_sq = tf.squeeze(c_conv)\n",
    "        return c_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeingModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MergeingModel, self).__init__()\n",
    "        self.seq_enc = SeqEncoder()\n",
    "        self.gene_enc = GeneEnc2()\n",
    "        self.dotlayer = dotLayer()\n",
    "        #self.gene_dec = GeneDec2()\n",
    "\n",
    "    def call(self, seq_batch, gene_batch):\n",
    "        seq_encoded  = self.seq_enc(seq_batch)\n",
    "        gene_encoded = self.gene_enc(gene_batch)\n",
    "        pred_peak    = self.dotlayer(seq_encoded, gene_encoded)\n",
    "        return pred_peak\n",
    "    \n",
    "    @tf.function\n",
    "    def gene_encoded(self, gene_batch):\n",
    "        encoded = self.gene_enc(gene_batch)\n",
    "        return encoded\n",
    "    \n",
    "    #def gene_decoded(self, gene_batch):\n",
    "    #    encoded = self.gene_enc(gene_batch)\n",
    "    #    decoded = self.gene_dec(gene_batch)\n",
    "    #    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_seq(model, dataset, data_x2 ):\n",
    "    \n",
    "    x, y, w1_0, w1_1 = dataset\n",
    "    y_bar = model(x, data_x2)\n",
    "    #print( y_bar.shape )\n",
    "\n",
    "    zeros = tf.cast(y<0.1, tf.float32)\n",
    "    weight0 = (w1_0 + TR_Y_W0_0) * zeros\n",
    "    weight1 = (w1_1 + TR_Y_W0_1) * (1-zeros)\n",
    "\n",
    "    sse0 = tf.math.reduce_mean( tf.math.square(y_bar)   * weight0 )\n",
    "    sse1 = tf.math.reduce_mean( tf.math.square(y_bar-y) * weight1 )\n",
    "    \n",
    "    return sse0, sse1\n",
    "\n",
    "#def loss_ae(model, data_x2 ):\n",
    "#    \n",
    "#    y_bar = model.gene_decoded(data_x2)\n",
    "#    \n",
    "#    sse_ae = tf.math.reduce_mean( tf.math.square(y_bar - data_x2) )\n",
    "#    \n",
    "#    return sse_ae\n",
    "\n",
    "def loss(model, dataset, data_x2 ):\n",
    "    l0, l1 = loss_seq(model, dataset, data_x2 )\n",
    "    #l2 = loss_ae(model, data_x2 )\n",
    "    return (l0 + l1)/2   #return l1*0.9+l2*0.1\n",
    "\n",
    "def train(loss, model, opt, dataset, data_x2 ):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient( loss( model, dataset, data_x2 ), model.trainable_variables)\n",
    "    gradient_variables = zip(gradients, model.trainable_variables)\n",
    "    opt.apply_gradients(gradient_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make batch and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_X1 = tf.data.Dataset.from_tensor_slices(TR_X1_SEQ)\n",
    "TF_X2 = tf.constant(TR_X2_GENE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_Y  = tf.data.Dataset.from_tensor_slices(TR_Y_PEAK)\n",
    "TF_W1_0 = tf.data.Dataset.from_tensor_slices(TR_Y_W1_0)\n",
    "TF_W1_1 = tf.data.Dataset.from_tensor_slices(TR_Y_W1_1)\n",
    "\n",
    "training_dataset = tf.data.Dataset.zip( (TF_X1, TF_Y, TF_W1_0, TF_W1_1) )\n",
    "training_dataset = training_dataset.batch( batch_size )\n",
    "training_dataset = training_dataset.shuffle( TR_X1_SEQ.shape[0] )\n",
    "training_dataset = training_dataset.prefetch( batch_size * 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = MergeingModel()\n",
    "l_loss = list()\n",
    "opt = tf.optimizers.Adamax(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/200 [0.37244132 0.8755114 ]\n",
      "Epoch 1/200 [0.41188198 0.73274434]\n",
      "Epoch 2/200 [0.42606094 0.68646866]\n",
      "Epoch 3/200 [0.4457121 0.6277728]\n",
      "Epoch 4/200 [0.4584627  0.58961916]\n",
      "Epoch 5/200 [0.458394   0.58898985]\n",
      "Epoch 6/200 [0.45804194 0.5888264 ]\n",
      "Epoch 7/200 [0.45770913 0.5882304 ]\n",
      "Epoch 8/200 [0.45752656 0.587844  ]\n",
      "Epoch 9/200 [0.45713258 0.58803886]\n",
      "Epoch 10/200 [0.45735583 0.58756244]\n",
      "Epoch 11/200 [0.45723847 0.5873822 ]\n",
      "Epoch 12/200 [0.45712227 0.58708024]\n",
      "Epoch 13/200 [0.45705754 0.58717   ]\n",
      "Epoch 14/200 [0.45678896 0.587222  ]\n",
      "Epoch 15/200 [0.45672783 0.5870999 ]\n",
      "Epoch 16/200 [0.45657447 0.5868363 ]\n",
      "Epoch 17/200 [0.45639205 0.5867493 ]\n",
      "Epoch 18/200 [0.45608902 0.5871898 ]\n",
      "Epoch 19/200 [0.45648614 0.58648247]\n",
      "Epoch 20/200 [0.45607045 0.58662385]\n",
      "Epoch 21/200 [0.45616016 0.5860436 ]\n",
      "Epoch 22/200 [0.45565984 0.5864961 ]\n",
      "Epoch 23/200 [0.45592257 0.5859049 ]\n",
      "Epoch 24/200 [0.45570758 0.58614814]\n",
      "Epoch 25/200 [0.45543268 0.58613193]\n",
      "Epoch 26/200 [0.45537204 0.58577317]\n",
      "Epoch 27/200 [0.4551548  0.58569825]\n",
      "Epoch 28/200 [0.45509887 0.5854594 ]\n",
      "Epoch 29/200 [0.45500267 0.58539724]\n",
      "Epoch 30/200 [0.4550804 0.5853652]\n",
      "Epoch 31/200 [0.45494702 0.58486456]\n",
      "Epoch 32/200 [0.4548732 0.5847056]\n",
      "Epoch 33/200 [0.45485502 0.58481723]\n",
      "Epoch 34/200 [0.45456502 0.5846179 ]\n",
      "Epoch 35/200 [0.45464668 0.58445674]\n",
      "Epoch 36/200 [0.45444056 0.5844226 ]\n",
      "Epoch 37/200 [0.45450637 0.58433765]\n",
      "Epoch 38/200 [0.45460603 0.5844331 ]\n",
      "Epoch 39/200 [0.45439035 0.58410823]\n",
      "Epoch 40/200 [0.4543824 0.5839074]\n",
      "Epoch 41/200 [0.45444334 0.5839036 ]\n",
      "Epoch 42/200 [0.4541207 0.5839399]\n",
      "Epoch 43/200 [0.45428598 0.5837829 ]\n",
      "Epoch 44/200 [0.45424247 0.58396596]\n",
      "Epoch 45/200 [0.45418903 0.5835649 ]\n",
      "Epoch 46/200 [0.45421034 0.58338755]\n",
      "Epoch 47/200 [0.4537852 0.5834655]\n",
      "Epoch 48/200 [0.4542547  0.58317477]\n",
      "Epoch 49/200 [0.4538608 0.5832188]\n",
      "Epoch 50/200 [0.45398775 0.5831902 ]\n",
      "Epoch 51/200 [0.45397627 0.583057  ]\n",
      "Epoch 52/200 [0.4538261  0.58322996]\n",
      "Epoch 53/200 [0.4537211 0.5830157]\n",
      "Epoch 54/200 [0.45399228 0.58273846]\n",
      "Epoch 55/200 [0.45355135 0.58270633]\n",
      "Epoch 56/200 [0.45348892 0.58306533]\n",
      "Epoch 57/200 [0.45384136 0.582395  ]\n",
      "Epoch 58/200 [0.45371342 0.58279806]\n",
      "Epoch 59/200 [0.45353597 0.58253044]\n",
      "Epoch 60/200 [0.45416382 0.5752207 ]\n",
      "Epoch 61/200 [0.4703987 0.5240802]\n",
      "Epoch 62/200 [0.4913821  0.49154952]\n",
      "Epoch 63/200 [0.49187165 0.48959908]\n",
      "Epoch 64/200 [0.4910801 0.4895972]\n",
      "Epoch 65/200 [0.49064824 0.489557  ]\n",
      "Epoch 66/200 [0.49034703 0.4893842 ]\n",
      "Epoch 67/200 [0.49075928 0.48881412]\n",
      "Epoch 68/200 [0.4901322  0.48912835]\n",
      "Epoch 69/200 [0.49011597 0.4890349 ]\n",
      "Epoch 70/200 [0.48964328 0.48915726]\n",
      "Epoch 71/200 [0.4897125  0.48905352]\n",
      "Epoch 72/200 [0.48962635 0.48877952]\n",
      "Epoch 73/200 [0.4898962  0.48864383]\n",
      "Epoch 74/200 [0.48936504 0.48889464]\n",
      "Epoch 75/200 [0.48924527 0.4887627 ]\n",
      "Epoch 76/200 [0.48949814 0.48830006]\n",
      "Epoch 77/200 [0.48916152 0.4887729 ]\n",
      "Epoch 78/200 [0.48907703 0.48845947]\n",
      "Epoch 79/200 [0.48918197 0.48846442]\n",
      "Epoch 80/200 [0.48911852 0.48840603]\n",
      "Epoch 81/200 [0.48866144 0.48872295]\n",
      "Epoch 82/200 [0.48932356 0.48796728]\n",
      "Epoch 83/200 [0.4888534 0.4882386]\n",
      "Epoch 84/200 [0.48885494 0.4881867 ]\n",
      "Epoch 85/200 [0.48879647 0.4883485 ]\n",
      "Epoch 86/200 [0.48877642 0.4881544 ]\n",
      "Epoch 87/200 [0.4887365  0.48823306]\n",
      "Epoch 88/200 [0.4890126 0.4878184]\n",
      "Epoch 89/200 [0.48821232 0.48843166]\n",
      "Epoch 90/200 [0.48903492 0.48750192]\n",
      "Epoch 91/200 [0.48865104 0.4878345 ]\n",
      "Epoch 92/200 [0.48837164 0.4880692 ]\n",
      "Epoch 93/200 [0.48824963 0.48809814]\n",
      "Epoch 94/200 [0.48883757 0.48734957]\n",
      "Epoch 95/200 [0.48865515 0.4874304 ]\n",
      "Epoch 96/200 [0.48834118 0.4876819 ]\n",
      "Epoch 97/200 [0.48846015 0.4875919 ]\n",
      "Epoch 98/200 [0.4883637  0.48743185]\n",
      "Epoch 99/200 [0.4881805  0.48733488]\n",
      "Epoch 100/200 [0.48825413 0.48729303]\n",
      "Epoch 101/200 [0.4880596  0.48743117]\n",
      "Epoch 102/200 [0.48855278 0.48694968]\n",
      "Epoch 103/200 [0.4886458  0.48696256]\n",
      "Epoch 104/200 [0.48816645 0.48715046]\n",
      "Epoch 105/200 [0.4875798 0.4876642]\n",
      "Epoch 106/200 [0.4884538  0.48675922]\n",
      "Epoch 107/200 [0.48827556 0.486866  ]\n",
      "Epoch 108/200 [0.4880345 0.4869699]\n",
      "Epoch 109/200 [0.48777434 0.48721611]\n",
      "Epoch 110/200 [0.4884931  0.48629242]\n",
      "Epoch 111/200 [0.4880709  0.48669282]\n",
      "Epoch 112/200 [0.48830876 0.48655733]\n",
      "Epoch 113/200 [0.48789236 0.48682424]\n",
      "Epoch 114/200 [0.4879974  0.48661974]\n",
      "Epoch 115/200 [0.48815483 0.4862989 ]\n",
      "Epoch 116/200 [0.48797897 0.48653647]\n",
      "Epoch 117/200 [0.48767877 0.48687616]\n",
      "Epoch 118/200 [0.48804215 0.48639706]\n",
      "Epoch 119/200 [0.4880624  0.48649526]\n",
      "Epoch 120/200 [0.48810902 0.48615018]\n",
      "Epoch 121/200 [0.48791236 0.48625633]\n",
      "Epoch 122/200 [0.48768008 0.48631844]\n",
      "Epoch 123/200 [0.4877871  0.48627505]\n",
      "Epoch 124/200 [0.48782057 0.48619002]\n",
      "Epoch 125/200 [0.48770216 0.48621643]\n",
      "Epoch 126/200 [0.48797143 0.48591533]\n",
      "Epoch 127/200 [0.48733443 0.4865715 ]\n",
      "Epoch 128/200 [0.4878924 0.485927 ]\n",
      "Epoch 129/200 [0.48754752 0.48614678]\n",
      "Epoch 130/200 [0.48740143 0.48624533]\n",
      "Epoch 131/200 [0.48761824 0.4859382 ]\n",
      "Epoch 132/200 [0.48774186 0.48574984]\n",
      "Epoch 133/200 [0.48746198 0.48595634]\n",
      "Epoch 134/200 [0.48732015 0.48603937]\n",
      "Epoch 135/200 [0.48776177 0.4855874 ]\n",
      "Epoch 136/200 [0.48765233 0.48571363]\n",
      "Epoch 137/200 [0.48741537 0.48578647]\n",
      "Epoch 138/200 [0.48727456 0.4858639 ]\n",
      "Epoch 139/200 [0.4873621  0.48575065]\n",
      "Epoch 140/200 [0.48787516 0.48527685]\n",
      "Epoch 141/200 [0.48715517 0.48580897]\n",
      "Epoch 142/200 [0.4871435 0.4856888]\n",
      "Epoch 143/200 [0.48757166 0.4853174 ]\n",
      "Epoch 144/200 [0.48776677 0.4851047 ]\n",
      "Epoch 145/200 [0.48710254 0.48574984]\n",
      "Epoch 146/200 [0.48757693 0.48532698]\n",
      "Epoch 147/200 [0.48732    0.48537427]\n",
      "Epoch 148/200 [0.48688698 0.4858024 ]\n",
      "Epoch 149/200 [0.48767167 0.48495692]\n",
      "Epoch 150/200 [0.48715138 0.48558828]\n",
      "Epoch 151/200 [0.48731917 0.48527777]\n",
      "Epoch 152/200 [0.48741364 0.48504215]\n",
      "Epoch 153/200 [0.48705566 0.485522  ]\n",
      "Epoch 154/200 [0.48714298 0.48533425]\n",
      "Epoch 155/200 [0.48703712 0.48538706]\n",
      "Epoch 156/200 [0.48729548 0.4849987 ]\n",
      "Epoch 157/200 [0.48711464 0.48510268]\n",
      "Epoch 158/200 [0.48715356 0.4852425 ]\n",
      "Epoch 159/200 [0.48726216 0.4850261 ]\n",
      "Epoch 160/200 [0.4871931  0.48508763]\n",
      "Epoch 161/200 [0.487236  0.4850121]\n",
      "Epoch 162/200 [0.4869198  0.48516098]\n",
      "Epoch 163/200 [0.486848   0.48539504]\n",
      "Epoch 164/200 [0.48733747 0.4846956 ]\n",
      "Epoch 165/200 [0.48682123 0.4851602 ]\n",
      "Epoch 166/200 [0.4872315  0.48476028]\n",
      "Epoch 167/200 [0.4871933  0.48478913]\n",
      "Epoch 168/200 [0.4867689  0.48530337]\n",
      "Epoch 169/200 [0.487219   0.48487064]\n",
      "Epoch 170/200 [0.48716486 0.48482728]\n",
      "Epoch 171/200 [0.4869965 0.484851 ]\n",
      "Epoch 172/200 [0.48728374 0.48462445]\n",
      "Epoch 173/200 [0.48695856 0.48502597]\n",
      "Epoch 174/200 [0.487356  0.4844925]\n",
      "Epoch 175/200 [0.48658046 0.48511708]\n",
      "Epoch 176/200 [0.48690438 0.48480108]\n",
      "Epoch 177/200 [0.4869508 0.4846382]\n",
      "Epoch 178/200 [0.48702103 0.48479542]\n",
      "Epoch 179/200 [0.4867417 0.4847172]\n",
      "Epoch 180/200 [0.48691583 0.48441923]\n",
      "Epoch 181/200 [0.48705542 0.4844297 ]\n",
      "Epoch 182/200 [0.48670623 0.48469985]\n",
      "Epoch 183/200 [0.48668134 0.48473513]\n",
      "Epoch 184/200 [0.48706853 0.48430997]\n",
      "Epoch 185/200 [0.48670852 0.48475215]\n",
      "Epoch 186/200 [0.48679554 0.48462188]\n",
      "Epoch 187/200 [0.48725107 0.4842205 ]\n",
      "Epoch 188/200 [0.4864946  0.48494834]\n",
      "Epoch 189/200 [0.48686847 0.48454782]\n",
      "Epoch 190/200 [0.48705468 0.48431608]\n",
      "Epoch 191/200 [0.48679242 0.4845907 ]\n",
      "Epoch 192/200 [0.48709682 0.48421398]\n",
      "Epoch 193/200 [0.48686507 0.48459682]\n",
      "Epoch 194/200 [0.4866835  0.48467004]\n",
      "Epoch 195/200 [0.4865073  0.48467916]\n",
      "Epoch 196/200 [0.48685223 0.48438126]\n",
      "Epoch 197/200 [0.487188  0.4840322]\n",
      "Epoch 198/200 [0.48683262 0.4843328 ]\n",
      "Epoch 199/200 [0.4868713  0.48418695]\n"
     ]
    }
   ],
   "source": [
    "starting_epoch = len(l_loss)\n",
    "for epoch in range(starting_epoch, epochs):\n",
    "       \n",
    "    epoch_loss = list()\n",
    "    for step, batch_features in enumerate(training_dataset):\n",
    "        train( loss, merged_model, opt, batch_features, TF_X2 )\n",
    "        loss_values = loss_seq( merged_model, batch_features, TF_X2 )\n",
    " \n",
    "        epoch_loss.append( loss_values )\n",
    "    \n",
    "    if epoch==0:\n",
    "        epoch0_loss = epoch_loss\n",
    "\n",
    "    loss_s01 = np.mean( np.array( epoch_loss ), axis=0 )\n",
    "    l_loss.append( loss_s01 ) #np.float( loss_ae(merged_model, TF_X2)), ) )\n",
    "    print('Epoch %d/%d' %(epoch, epochs), loss_s01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f360c2ef190>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(epoch0_loss)).plot(logx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3704fab9d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(l_loss)).plot(logx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gz.open('OUTPUT/loss_dup.pkl.gz', 'wb') as f:\n",
    "    pkl.dump((epoch0_loss, l_loss), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3724b3ebbd47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'error' is not defined"
     ]
    }
   ],
   "source": [
    "error(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_encoded10 = np.array(merged_model.gene_enc(TR_X2_GENE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with gz.open('OUTPUT/gene_enc.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(gene_encoded10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(gene_encoded10.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(TR_X1_SEQ)\n",
    "L_pred = list()\n",
    "\n",
    "for x_id in range(0, total_len, 1000):\n",
    "    TR_1 = TR_X1_SEQ[x_id:x_id+1000]\n",
    "\n",
    "    pred = merged_model(TR_1, TR_X2_GENE)\n",
    "    NP_pred = np.array(pred, dtype=np.float16)\n",
    "    \n",
    "    L_pred.append(NP_pred)\n",
    "\n",
    "NP_imputed = np.concatenate(L_pred)\n",
    "del L_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_Nucl = NP_imputed[:,:,0]\n",
    "NP_Methyl = NP_imputed[:,:,1]\n",
    "\n",
    "pd.DataFrame(NP_Nucl).to_csv('OUTPUT/pred_score_nucl.tsv', sep='\\t', header=None, index=None)\n",
    "pd.DataFrame(NP_Methyl).to_csv('OUTPUT/pred_score_methyl.tsv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Nucl = TR_Y_PEAK[:,:,0]\n",
    "Y_Methyl = TR_Y_PEAK[:,:,1]\n",
    "\n",
    "pd.DataFrame(Y_Nucl).to_csv('OUTPUT/peak_nucl.tsv', sep='\\t', header=None, index=None)\n",
    "pd.DataFrame(Y_Methyl).to_csv('OUTPUT/peak_methyl.tsv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error(Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make batch and train 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_Y_PEAK_10pct = TR_Y_PEAK * (np.random.binomial(1, 0.9, TR_Y_PEAK.shape)).astype('float32')\n",
    "TR_Y_ZERO_10pct = (TR_Y_PEAK_10pct < 0.1).astype('float32')\n",
    "\n",
    "TR_Y_W0_0 = 1/(TR_Y_ZERO_10pct.mean(axis=0, keepdims=True) + 0.01) + 0.01\n",
    "TR_Y_W1_0 = 1/(TR_Y_ZERO_10pct.mean(axis=1, keepdims=True) + 0.01) + 0.01\n",
    "TR_Y_W0_1 = 1/(1-1/TR_Y_W0_0)\n",
    "TR_Y_W1_1 = 1/(1-1/TR_Y_W1_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_X1 = tf.data.Dataset.from_tensor_slices(TR_X1_SEQ)\n",
    "TF_X2 = tf.constant(TR_X2_GENE)\n",
    "TF_Y  = tf.data.Dataset.from_tensor_slices(TR_Y_PEAK_10pct)\n",
    "TF_W1_0 = tf.data.Dataset.from_tensor_slices(TR_Y_W1_0)\n",
    "TF_W1_1 = tf.data.Dataset.from_tensor_slices(TR_Y_W1_1)\n",
    "\n",
    "training_dataset = tf.data.Dataset.zip( (TF_X1, TF_Y, TF_W1_0, TF_W1_1) )\n",
    "training_dataset = training_dataset.batch( batch_size )\n",
    "training_dataset = training_dataset.shuffle( TR_X1_SEQ.shape[0] )\n",
    "training_dataset = training_dataset.prefetch( batch_size * 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = MergeingModel()\n",
    "l_loss = list()\n",
    "opt = tf.optimizers.Adamax(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starting_epoch = len(l_loss)\n",
    "for epoch in range(starting_epoch, epochs):\n",
    "       \n",
    "    epoch_loss = list()\n",
    "    for step, batch_features in enumerate(training_dataset):\n",
    "        train( loss, merged_model, opt, batch_features, TF_X2 )\n",
    "        loss_values = loss_seq( merged_model, batch_features, TF_X2 )\n",
    " \n",
    "        epoch_loss.append( loss_values )\n",
    "\n",
    "    loss_sum = np.array( epoch_loss ).mean()\n",
    "    l_loss.append( (loss_sum, 0) ) #np.float( loss_ae(merged_model, TF_X2)), ) )\n",
    "    print('Epoch %d/%d' %(epoch, epochs), loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(l_loss)).plot(logx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_encoded10 = np.array(merged_model.gene_enc(TR_X2_GENE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with gz.open('OUTPUT/gene_enc_10pct.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(gene_encoded10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(gene_encoded10.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(TR_X1_SEQ)\n",
    "L_pred = list()\n",
    "\n",
    "for x_id in range(0, total_len, 1000):\n",
    "    TR_1 = TR_X1_SEQ[x_id:x_id+1000]\n",
    "\n",
    "    pred = merged_model(TR_1, TR_X2_GENE)\n",
    "    NP_pred = np.array(pred, dtype=np.float16)\n",
    "    \n",
    "    L_pred.append(NP_pred)\n",
    "\n",
    "NP_imputed = np.concatenate(L_pred)\n",
    "del L_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_Nucl = NP_imputed[:,:,0]\n",
    "NP_Methyl = NP_imputed[:,:,1]\n",
    "\n",
    "pd.DataFrame(NP_Nucl).to_csv('OUTPUT/pred_score_nucl_10pct.tsv', sep='\\t', header=None, index=None)\n",
    "pd.DataFrame(NP_Methyl).to_csv('OUTPUT/pred_score_methyl_10pct.tsv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Nucl = TR_Y_PEAK_10pct[:,:,0]\n",
    "Y_Methyl = TR_Y_PEAK_10pct[:,:,1]\n",
    "\n",
    "pd.DataFrame(Y_Nucl).to_csv('OUTPUT/peak_nucl_10pct.tsv', sep='\\t', header=None, index=None)\n",
    "pd.DataFrame(Y_Methyl).to_csv('OUTPUT/peak_methyl_10pct.tsv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make batch and train 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_Y_PEAK_20pct = TR_Y_PEAK * (np.random.binomial(1, 0.8, TR_Y_PEAK.shape)).astype('float32')\n",
    "TR_Y_ZERO_20pct = (TR_Y_PEAK_20pct < 0.1).astype('float32')\n",
    "\n",
    "TR_Y_W0_0 = 1/(TR_Y_ZERO_20pct.mean(axis=0, keepdims=True) + 0.01) + 0.01\n",
    "TR_Y_W1_0 = 1/(TR_Y_ZERO_20pct.mean(axis=1, keepdims=True) + 0.01) + 0.01\n",
    "TR_Y_W0_1 = 1/(1-1/TR_Y_W0_0)\n",
    "TR_Y_W1_1 = 1/(1-1/TR_Y_W1_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_X1 = tf.data.Dataset.from_tensor_slices(TR_X1_SEQ)\n",
    "TF_X2 = tf.constant(TR_X2_GENE)\n",
    "TF_Y  = tf.data.Dataset.from_tensor_slices(TR_Y_PEAK_20pct)\n",
    "TF_W1_0 = tf.data.Dataset.from_tensor_slices(TR_Y_W1_0)\n",
    "TF_W1_1 = tf.data.Dataset.from_tensor_slices(TR_Y_W1_1)\n",
    "\n",
    "training_dataset = tf.data.Dataset.zip( (TF_X1, TF_Y, TF_W1_0, TF_W1_1) )\n",
    "training_dataset = training_dataset.batch( batch_size )\n",
    "training_dataset = training_dataset.shuffle( TR_X1_SEQ.shape[0] )\n",
    "training_dataset = training_dataset.prefetch( batch_size * 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = MergeingModel()\n",
    "l_loss = list()\n",
    "opt = tf.optimizers.Adamax(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starting_epoch = len(l_loss)\n",
    "for epoch in range(starting_epoch, epochs):\n",
    "       \n",
    "    epoch_loss = list()\n",
    "    for step, batch_features in enumerate(training_dataset):\n",
    "        train( loss, merged_model, opt, batch_features, TF_X2 )\n",
    "        loss_values = loss_seq( merged_model, batch_features, TF_X2 )\n",
    " \n",
    "        epoch_loss.append( loss_values )\n",
    "\n",
    "    loss_sum = np.array( epoch_loss ).mean()\n",
    "    l_loss.append( (loss_sum, 0) ) #np.float( loss_ae(merged_model, TF_X2)), ) )\n",
    "    print('Epoch %d/%d' %(epoch, epochs), loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(l_loss)).plot(logx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_encoded10 = np.array(merged_model.gene_enc(TR_X2_GENE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with gz.open('OUTPUT/gene_enc_20pct.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(gene_encoded10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(gene_encoded10.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(TR_X1_SEQ)\n",
    "L_pred = list()\n",
    "\n",
    "for x_id in range(0, total_len, 1000):\n",
    "    TR_1 = TR_X1_SEQ[x_id:x_id+1000]\n",
    "\n",
    "    pred = merged_model(TR_1, TR_X2_GENE)\n",
    "    NP_pred = np.array(pred, dtype=np.float16)\n",
    "    \n",
    "    L_pred.append(NP_pred)\n",
    "\n",
    "NP_imputed = np.concatenate(L_pred)\n",
    "del L_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_Nucl = NP_imputed[:,:,0]\n",
    "NP_Methyl = NP_imputed[:,:,1]\n",
    "\n",
    "pd.DataFrame(NP_Nucl).to_csv('OUTPUT/pred_score_nucl_20pct.tsv', sep='\\t', header=None, index=None)\n",
    "pd.DataFrame(NP_Methyl).to_csv('OUTPUT/pred_score_methyl_20pct.tsv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Nucl = TR_Y_PEAK_20pct[:,:,0]\n",
    "Y_Methyl = TR_Y_PEAK_20pct[:,:,1]\n",
    "\n",
    "pd.DataFrame(Y_Nucl).to_csv('OUTPUT/peak_nucl_20pct.tsv', sep='\\t', header=None, index=None)\n",
    "pd.DataFrame(Y_Methyl).to_csv('OUTPUT/peak_methyl_20pct.tsv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make batch and train 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_Y_PEAK_50pct = TR_Y_PEAK * (np.random.binomial(1, 0.5, TR_Y_PEAK.shape)).astype('float32')\n",
    "TR_Y_ZERO_50pct = (TR_Y_PEAK_50pct < 0.1).astype('float32')\n",
    "\n",
    "TR_Y_W0_0 = 1/(TR_Y_ZERO_50pct.mean(axis=0, keepdims=True) + 0.01) + 0.01\n",
    "TR_Y_W1_0 = 1/(TR_Y_ZERO_50pct.mean(axis=1, keepdims=True) + 0.01) + 0.01\n",
    "TR_Y_W0_1 = 1/(1-1/TR_Y_W0_0)\n",
    "TR_Y_W1_1 = 1/(1-1/TR_Y_W1_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_X1 = tf.data.Dataset.from_tensor_slices(TR_X1_SEQ)\n",
    "TF_X2 = tf.constant(TR_X2_GENE)\n",
    "TF_Y  = tf.data.Dataset.from_tensor_slices(TR_Y_PEAK_50pct)\n",
    "TF_W1_0 = tf.data.Dataset.from_tensor_slices(TR_Y_W1_0)\n",
    "TF_W1_1 = tf.data.Dataset.from_tensor_slices(TR_Y_W1_1)\n",
    "\n",
    "training_dataset = tf.data.Dataset.zip( (TF_X1, TF_Y, TF_W1_0, TF_W1_1) )\n",
    "training_dataset = training_dataset.batch( batch_size )\n",
    "training_dataset = training_dataset.shuffle( TR_X1_SEQ.shape[0] )\n",
    "training_dataset = training_dataset.prefetch( batch_size * 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = MergeingModel()\n",
    "l_loss = list()\n",
    "opt = tf.optimizers.Adamax(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starting_epoch = len(l_loss)\n",
    "for epoch in range(starting_epoch, epochs):\n",
    "       \n",
    "    epoch_loss = list()\n",
    "    for step, batch_features in enumerate(training_dataset):\n",
    "        train( loss, merged_model, opt, batch_features, TF_X2 )\n",
    "        loss_values = loss_seq( merged_model, batch_features, TF_X2 )\n",
    " \n",
    "        epoch_loss.append( loss_values )\n",
    "\n",
    "    loss_sum = np.array( epoch_loss ).mean()\n",
    "    l_loss.append( (loss_sum, 0) ) #np.float( loss_ae(merged_model, TF_X2)), ) )\n",
    "    print('Epoch %d/%d' %(epoch, epochs), loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(l_loss)).plot(logx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_encoded10 = np.array(merged_model.gene_enc(TR_X2_GENE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with gz.open('OUTPUT/gene_enc_50pct.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(gene_encoded10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(gene_encoded10.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(TR_X1_SEQ)\n",
    "L_pred = list()\n",
    "\n",
    "for x_id in range(0, total_len, 1000):\n",
    "    TR_1 = TR_X1_SEQ[x_id:x_id+1000]\n",
    "\n",
    "    pred = merged_model(TR_1, TR_X2_GENE)\n",
    "    NP_pred = np.array(pred, dtype=np.float16)\n",
    "    \n",
    "    L_pred.append(NP_pred)\n",
    "\n",
    "NP_imputed = np.concatenate(L_pred)\n",
    "del L_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP_Nucl = NP_imputed[:,:,0]\n",
    "NP_Methyl = NP_imputed[:,:,1]\n",
    "\n",
    "pd.DataFrame(NP_Nucl).to_csv('OUTPUT/pred_score_nucl_50pct.tsv', sep='\\t', header=None, index=None)\n",
    "pd.DataFrame(NP_Methyl).to_csv('OUTPUT/pred_score_methyl_50pct.tsv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Nucl = TR_Y_PEAK_50pct[:,:,0]\n",
    "Y_Methyl = TR_Y_PEAK_50pct[:,:,1]\n",
    "\n",
    "pd.DataFrame(Y_Nucl).to_csv('OUTPUT/peak_nucl_50pct.tsv', sep='\\t', header=None, index=None)\n",
    "pd.DataFrame(Y_Methyl).to_csv('OUTPUT/peak_methyl_50pct.tsv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_cell_id = list(pd.read_csv('INPUT_1/ID_CELL.txt', header=None)[0])\n",
    "pd.DataFrame(gene_encoded10, index=L_cell_id).to_csv('OUTPUT/gene_enc.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = merged_model(TR_X1_SEQ[:1000], TR_X2_GENE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_0 = NP_imputed[:total_len//2]\n",
    "y_hat_1 = NP_imputed[total_len//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_mean = (y_hat_0 + y_hat_1)/2\n",
    "y_hat_diff = np.abs(y_hat_0 - y_hat_1)\n",
    "del y_hat_0\n",
    "del y_hat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = (TR_Y_PEAK[:total_len//2]).astype(np.int8)\n",
    "nT = T.sum()\n",
    "F = (1-T)\n",
    "nF = F.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutline_list = np.concatenate(\n",
    "    (np.arange(0, 0.3, 0.1),\n",
    "     np.arange(0.31, 0.69, 0.01),\n",
    "     np.arange(0.7, 1.0, 0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutline_list = np.arange(0, 1.01,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_stat = list()\n",
    "for diff_weight in np.arange(-0.5, 0.501, 0.25):\n",
    "    y_hat_adj = y_hat_mean + diff_weight * y_hat_diff\n",
    "    \n",
    "    for cutline in cutline_list:\n",
    "        adj = 0.99999 - cutline\n",
    "        P = (y_hat_adj + adj).astype(np.int8)\n",
    "        nP = P.sum()\n",
    "        \n",
    "        TP = T * P\n",
    "        nTP = TP.sum()\n",
    "        #print(nP, nTP)\n",
    "        if nP==0:\n",
    "            Prec = 1.0\n",
    "            Recall = 0.0\n",
    "        else:\n",
    "            Prec   = nTP/nP\n",
    "            Recall = nTP/nT\n",
    "        \n",
    "        FP = F * P\n",
    "        nFP = FP.sum()\n",
    "        FPR = nFP/nF\n",
    "        \n",
    "        F1 = 2*Prec*Recall/(Prec+Recall)\n",
    "        F2 = 5*Prec*Recall/(4*Prec+Recall)\n",
    "\n",
    "        print([diff_weight, cutline, Prec, Recall, F1, F2, FPR])\n",
    "        L_stat.append([diff_weight, cutline, Prec, Recall, F1, F2, FPR])\n",
    "    del y_hat_adj\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_stat = pd.DataFrame(L_stat, columns=['diff_weight', 'cutline', 'Prec', 'Recall', 'F1', 'F2', 'FPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_stat.to_csv('stat_dup.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR(ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.array(DF_stat['F1']).reshape(5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.array(DF_stat['F2']).reshape(5,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='cutline', y='F2', hue='diff_weight', data=DF_stat, palette='Reds')\n",
    "sns.lineplot(x='cutline', y='F1', hue='diff_weight', data=DF_stat, palette='Blues')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center=(DF_stat['cutline']>0.4) & (DF_stat['cutline'] <0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_stat_center = DF_stat[ center ]\n",
    "sns.lineplot(x='cutline', y='F1', hue='diff_weight', data=DF_stat_center, palette='Reds')\n",
    "sns.lineplot(x='cutline', y='F2', hue='diff_weight', data=DF_stat_center, palette='Blues')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='cutline', y='Recall', hue='diff_weight', data=DF_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='cutline', y='Prec', hue='diff_weight', data=DF_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ing for the group fiksns.lineplot(x='cutline', y='FPR', hue='diff_weight', data=DF_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='FPR', y='Recall', hue='diff_weight', data=DF_stat)\n",
    "sns.lineplot(x=[0,1], y=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_stat2 = list()\n",
    "y_hat_adj = y_hat_mean\n",
    "    \n",
    "for cutline in cutline_list:\n",
    "    adj = 0.99999 - cutline\n",
    "    P = (y_hat_adj + adj).astype(np.int8)\n",
    "    nP = P.sum()\n",
    "\n",
    "    TP = T * P\n",
    "    nTP = TP.sum()\n",
    "\n",
    "    if nP==0:\n",
    "        Prec = 1.0\n",
    "        Recall = 0.0\n",
    "    else:\n",
    "        Prec   = nTP/nP\n",
    "        Recall = nTP/nT\n",
    "\n",
    "    FP = F * P\n",
    "    nFP = FP.sum()\n",
    "    \n",
    "    for hR in [0.0, 0.15, 0.3, 0.45]:\n",
    "        hTr  = nF * hR\n",
    "        hTPr = hTr * Recall\n",
    "        hFPR  = (nFP - hTPr)/(nF - hTr)\n",
    "\n",
    "        print([cutline, hR, Recall, hFPR])\n",
    "        L_stat2.append([cutline, hR, Recall, hFPR])\n",
    "del y_hat_adj\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_stat2 = pd.DataFrame(L_stat2, columns=['cutline', 'hidden_rate', 'Recall', 'FPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='FPR', y='Recall', hue='hidden_rate', data=DF_stat2)\n",
    "sns.lineplot(x=[0,1], y=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_stat0 = list()\n",
    "y0 = y_hat_mean[:,:,0]\n",
    "T0 = T[:,:,0]\n",
    "nT0 = T0.sum()\n",
    "F0 = F[:,:,0]\n",
    "nF0 = F0.sum()\n",
    "    \n",
    "for cutline in cutline_list:\n",
    "    adj = 0.99999 - cutline\n",
    "    P = (y0 + adj).astype(np.int8)\n",
    "    nP = P.sum()\n",
    "\n",
    "    TP = T0 * P\n",
    "    nTP = TP.sum()\n",
    "\n",
    "    if nP==0:\n",
    "        Prec = 1.0\n",
    "        Recall = 0.0\n",
    "    else:\n",
    "        Prec   = nTP/nP\n",
    "        Recall = nTP/nT0\n",
    "\n",
    "    FP = F0 * P\n",
    "    nFP = FP.sum()\n",
    "    \n",
    "    for hR in [0.0, 0.15, 0.3, 0.45]:\n",
    "        hTr  = nF0 * hR\n",
    "        hTPr = hTr * Recall\n",
    "        hFPR  = (nFP - hTPr)/(nF0 - hTr)\n",
    "\n",
    "        print([cutline, hR, Recall, hFPR])\n",
    "        L_stat0.append([cutline, hR, Recall, hFPR])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_stat0 = pd.DataFrame(L_stat0, columns=['cutline', 'hidden_rate', 'Recall', 'FPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='FPR', y='Recall', hue='hidden_rate', data=DF_stat0)\n",
    "sns.lineplot(x=[0,1], y=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_stat1 = list()\n",
    "y1 = y_hat_mean[:,:,1]\n",
    "T1 = T[:,:,1]\n",
    "nT1 = T1.sum()\n",
    "F1 = F[:,:,1]\n",
    "nF1 = F1.sum()\n",
    "    \n",
    "for cutline in cutline_list:\n",
    "    adj = 0.99999 - cutline\n",
    "    P = (y1 + adj).astype(np.int8)\n",
    "    nP = P.sum()\n",
    "\n",
    "    TP = T1 * P\n",
    "    nTP = TP.sum()\n",
    "\n",
    "    if nP==0:\n",
    "        Prec = 1.0\n",
    "        Recall = 0.0\n",
    "    else:\n",
    "        Prec   = nTP/nP\n",
    "        Recall = nTP/nT1\n",
    "\n",
    "    FP = F1 * P\n",
    "    nFP = FP.sum()\n",
    "    \n",
    "    for hR in [0.0, 0.15, 0.3, 0.45]:\n",
    "        hTr  = nF1 * hR\n",
    "        hTPr = hTr * Recall\n",
    "        hFPR  = (nFP - hTPr)/(nF1 - hTr)\n",
    "\n",
    "        print([cutline, hR, Recall, hFPR])\n",
    "        L_stat1.append([cutline, hR, Recall, hFPR])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_stat1 = pd.DataFrame(L_stat1, columns=['cutline', 'hidden_rate', 'Recall', 'FPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='FPR', y='Recall', hue='hidden_rate', data=DF_stat1)\n",
    "sns.lineplot(x=[0,1], y=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
